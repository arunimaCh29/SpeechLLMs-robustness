{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff8b24a2-03f7-40fa-8139-a9d45721cf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78c88f35-b63d-4d7c-8f59-e56e5494063f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully logged in to Hugging Face!\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "import os\n",
    "\n",
    "token_file_path = 'secrets.txt'\n",
    "\n",
    "if os.path.exists(token_file_path):\n",
    "    try:\n",
    "        with open(token_file_path, 'r') as f:\n",
    "            hf_token = f.read().strip()  # .strip() removes any leading/trailing whitespace\n",
    "\n",
    "        login(hf_token)\n",
    "        print(\"Successfully logged in to Hugging Face!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while trying to read the token file or log in: {e}\")\n",
    "else:\n",
    "    print(f\"Token file not found at {token_file_path}. Please create the file and add your token.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f7dedc9-7e03-4442-b8e3-09ee498bc53e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[31mSignature:\u001b[39m\n",
       "login(\n",
       "    token: Optional[str] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
       "    *,\n",
       "    add_to_git_credential: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
       "    new_session: bool = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
       "    write_permission: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
       ") -> \u001b[38;5;28;01mNone\u001b[39;00m\n",
       "\u001b[31mDocstring:\u001b[39m\n",
       "Login the machine to access the Hub.\n",
       "\n",
       "The `token` is persisted in cache and set as a git credential. Once done, the machine\n",
       "is logged in and the access token will be available across all `huggingface_hub`\n",
       "components. If `token` is not provided, it will be prompted to the user either with\n",
       "a widget (in a notebook) or via the terminal.\n",
       "\n",
       "To log in from outside of a script, one can also use `hf auth login` which is\n",
       "a cli command that wraps [`login`].\n",
       "\n",
       "<Tip>\n",
       "\n",
       "[`login`] is a drop-in replacement method for [`notebook_login`] as it wraps and\n",
       "extends its capabilities.\n",
       "\n",
       "</Tip>\n",
       "\n",
       "<Tip>\n",
       "\n",
       "When the token is not passed, [`login`] will automatically detect if the script runs\n",
       "in a notebook or not. However, this detection might not be accurate due to the\n",
       "variety of notebooks that exists nowadays. If that is the case, you can always force\n",
       "the UI by using [`notebook_login`] or [`interpreter_login`].\n",
       "\n",
       "</Tip>\n",
       "\n",
       "Args:\n",
       "    token (`str`, *optional*):\n",
       "        User access token to generate from https://huggingface.co/settings/token.\n",
       "    add_to_git_credential (`bool`, defaults to `False`):\n",
       "        If `True`, token will be set as git credential. If no git credential helper\n",
       "        is configured, a warning will be displayed to the user. If `token` is `None`,\n",
       "        the value of `add_to_git_credential` is ignored and will be prompted again\n",
       "        to the end user.\n",
       "    new_session (`bool`, defaults to `True`):\n",
       "        If `True`, will request a token even if one is already saved on the machine.\n",
       "    write_permission (`bool`):\n",
       "        Ignored and deprecated argument.\n",
       "Raises:\n",
       "    [`ValueError`](https://docs.python.org/3/library/exceptions.html#ValueError)\n",
       "        If an organization token is passed. Only personal account tokens are valid\n",
       "        to log in.\n",
       "    [`ValueError`](https://docs.python.org/3/library/exceptions.html#ValueError)\n",
       "        If token is invalid.\n",
       "    [`ImportError`](https://docs.python.org/3/library/exceptions.html#ImportError)\n",
       "        If running in a notebook but `ipywidgets` is not installed.\n",
       "\u001b[31mFile:\u001b[39m      ~/.local/lib/python3.11/site-packages/huggingface_hub/_login.py\n",
       "\u001b[31mType:\u001b[39m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd410b35-bc93-4adf-9b3a-2a879d72b91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14473775\n",
      "data_source\n",
      "common_voice_en    186\n",
      "common_voice_de     88\n",
      "vctk_en             13\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from src.data_utils import SIFT50MDataset\n",
    "import os\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "sift_dataset = load_dataset(\n",
    "    'amazon-agi/SIFT-50M',\n",
    "    name='closed_ended_content_level',\n",
    "    split='train',\n",
    "    trust_remote_code=True\n",
    ")\n",
    "sift_dataset = sift_dataset.shuffle(seed=90)\n",
    "df = sift_dataset.select(range(1000)).to_pandas()\n",
    "print(len(sift_dataset))\n",
    "allowed_values = [\"common_voice_de\",'vctk_en','common_voice_en'] # \"multilingual_librispeech_de\" \"common_voice_en\" The datasets were taking too long to get donwloaded so I restricted it to certain subsets\n",
    "\n",
    "filtered_df = df[df[\"data_source\"].isin(allowed_values)]\n",
    "\n",
    "# Count number of entries per value\n",
    "counts = filtered_df[\"data_source\"].value_counts()\n",
    "print(counts)\n",
    "sift_data = Dataset.from_pandas(filtered_df)\n",
    "# Define the base datasets paths (replace with your actual paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c9201f-8043-4da9-964f-d23b91a4d203",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_len = len(sift_data)\n",
    "eval_len = int(0.2*total_len)\n",
    "\n",
    "eval_ds = sift_data.select(range(eval_len))\n",
    "train_ds = sift_data.select(range(eval_len,total_len))\n",
    "\n",
    "base_datasets_root = \"/home/jovyan/.cache/huggingface/datasets\"\n",
    "base_datasets_paths = {\n",
    "    \"common_voice_de\": None, # No longer needs a path, handled by load_dataset\n",
    "    #\"multilingual_librispeech_de\": None, # No longer needs a path, handled by load_dataset\n",
    "    \"common_voice_en\": None, # No longer needs a path, handled by load_dataset\n",
    "    \"vctk_en\": \"./vctk_corpus\" # VCTK still needs a root path for torchaudio\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee0c7dc-088f-4c84-bac5-ba7a77e7f17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Qwen2AudioForConditionalGeneration, AutoProcessor\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-Audio-7B-Instruct\")\n",
    "model = Qwen2AudioForConditionalGeneration.from_pretrained(\"Qwen/Qwen2-Audio-7B\", device_map=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b743423-8059-4ce4-83a4-5cb6c370dc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "from dataset import DataLoader\n",
    "\n",
    "sift_iterable_dataset_eval = SIFT50MDataset(sift_dataset=eval_ds, base_datasets_paths=base_datasets_paths)\n",
    "\n",
    "loader = DataLoader(sift_iterable, )\n",
    "\n",
    "for conversation in sift_iterable_dataset_eval:\n",
    "    print(\n",
    "    text = processor.apply_chat_template(conversation['messages'], add_generation_prompt=True, tokenize=False)\n",
    "    audios = []\n",
    "    found_audio_paths = []\n",
    "    def find_audio_paths(content_list):\n",
    "        paths = []\n",
    "        if not isinstance(content_list, (list, tuple)):\n",
    "            content_list = [content_list]\n",
    "        for item in content_list:\n",
    "            if isinstance(item, dict) and 'audio_path' in item.keys() and item['audio_path'] is not None:\n",
    "                paths.append(item['audio_path'])\n",
    "            elif isinstance(item, dict) and 'content' in item.keys():\n",
    "                paths.extend(find_audio_paths(item['content']))\n",
    "            elif isinstance(item, (list, tuple)):\n",
    "                paths.extend(find_audio_paths(item))\n",
    "        return paths\n",
    "\n",
    "    for role_entry in conversation['messages']:\n",
    "        if 'content' in role_entry and 'role' in role_entry and role_entry['role'] != 'assistant':\n",
    "            found_audio_paths.extend(find_audio_paths(role_entry['content']))\n",
    "    \n",
    "    audio_signals = []\n",
    "    for path in found_audio_paths:\n",
    "        if os.path.exists(path):\n",
    "            audio, _ = librosa.load(\n",
    "                path,\n",
    "                sr=processor.feature_extractor.sampling_rate\n",
    "            )\n",
    "            audio_signals.append(audio)\n",
    "        else:\n",
    "            # Log which file was not found\n",
    "            print(f\"File not found: {path}. This may cause an audio-token mismatch.\")\n",
    "\n",
    "    inputs = processor(text=text, audio=audio_signals, return_tensors=\"pt\", padding=True)\n",
    "    inputs.input_ids = inputs.input_ids.to(\"cuda\")\n",
    "\n",
    "    generate_ids = model.generate(**inputs, max_length=512)\n",
    "    generate_ids = generate_ids[:, inputs.input_ids.size(1):]\n",
    "\n",
    "    response = processor.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "    print(response)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:conda-ainmc]",
   "language": "python",
   "name": "conda-env-conda-ainmc-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
